{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13039313,"sourceType":"datasetVersion","datasetId":8256693},{"sourceId":13039682,"sourceType":"datasetVersion","datasetId":8256982}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom datasets import load_dataset\nfrom torchvision.transforms import ToTensor\nfrom torchvision import transforms","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T13:31:37.461995Z","iopub.execute_input":"2025-09-12T13:31:37.462294Z","iopub.status.idle":"2025-09-12T13:31:51.394614Z","shell.execute_reply.started":"2025-09-12T13:31:37.462273Z","shell.execute_reply":"2025-09-12T13:31:51.393827Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from datasets import load_dataset\nfrom sklearn.preprocessing import LabelEncoder\n\ndataset = load_dataset(\"Isamu136/big-animal-dataset\")\n\ncaptions = dataset['train']['caption']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T13:31:51.395898Z","iopub.execute_input":"2025-09-12T13:31:51.396257Z","iopub.status.idle":"2025-09-12T13:32:06.430159Z","shell.execute_reply.started":"2025-09-12T13:31:51.396239Z","shell.execute_reply":"2025-09-12T13:32:06.429301Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/554 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4d2a6bfa93b4f078e50a87cb8d55ad4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00000-of-00003-b0e3a3345037ee(…):   0%|          | 0.00/525M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d57507193be94b14893cf232c82b4dcf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00001-of-00003-32ac7a4ee78dc9(…):   0%|          | 0.00/502M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3941768fc474cddb2baccb0ab383141"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00002-of-00003-e455e1e1c98858(…):   0%|          | 0.00/781M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2dff632e70647409c64703b11acc5cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/62149 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66d3f215f0714b869f9d776fc2ff9e8b"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"le = LabelEncoder()\ncaption_ids = le.fit_transform(captions)\nclass_names = list(le.classes_)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T13:32:06.430888Z","iopub.execute_input":"2025-09-12T13:32:06.431395Z","iopub.status.idle":"2025-09-12T13:32:06.498774Z","shell.execute_reply.started":"2025-09-12T13:32:06.431372Z","shell.execute_reply":"2025-09-12T13:32:06.497167Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"dataset['train'] = dataset['train'].add_column('lable', caption_ids)\ndataset['train'] = dataset['train'].remove_columns(\"caption\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T13:32:06.501128Z","iopub.execute_input":"2025-09-12T13:32:06.501457Z","iopub.status.idle":"2025-09-12T13:32:12.540195Z","shell.execute_reply.started":"2025-09-12T13:32:06.501417Z","shell.execute_reply":"2025-09-12T13:32:12.539400Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# from datasets import load_dataset\n# from sklearn.preprocessing import LabelEncoder\n\n# dataset = load_dataset(\"Isamu136/big-animal-dataset\")\n\n# captions = dataset['train']['caption']\n# le = LabelEncoder()\n# caption_ids = le.fit_transform(captions)\n# dataset['train'] = dataset['train'].add_column('lable', caption_ids)\n# dataset['train'] = dataset['train'].remove_columns(\"caption\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T13:32:12.541196Z","iopub.execute_input":"2025-09-12T13:32:12.541484Z","iopub.status.idle":"2025-09-12T13:32:13.360459Z","shell.execute_reply.started":"2025-09-12T13:32:12.541458Z","shell.execute_reply":"2025-09-12T13:32:13.359656Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"dataset_split = dataset[\"train\"].train_test_split(test_size=0.2, seed=42)\ntrain_valid = dataset_split[\"train\"].train_test_split(test_size=0.25, seed=42)\ndataset = {\n    \"train\": train_valid[\"train\"],\n    \"validation\": train_valid[\"test\"],\n    \"test\": dataset_split[\"test\"]\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T13:32:13.361473Z","iopub.execute_input":"2025-09-12T13:32:13.361777Z","iopub.status.idle":"2025-09-12T13:32:14.456996Z","shell.execute_reply.started":"2025-09-12T13:32:13.361751Z","shell.execute_reply":"2025-09-12T13:32:14.456125Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# dataset['train'][1000]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T13:32:14.457612Z","iopub.execute_input":"2025-09-12T13:32:14.457813Z","iopub.status.idle":"2025-09-12T13:32:15.133502Z","shell.execute_reply.started":"2025-09-12T13:32:14.457797Z","shell.execute_reply":"2025-09-12T13:32:15.132699Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from torch.utils.data import Dataset\n\nclass ToRGB(object):\n    def __call__(self, img):\n        return img.convert('RGB')\n\ntransform_train = transforms.Compose([\n    ToRGB(),\n    transforms.RandomCrop(32, padding=4),\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),\n    transforms.RandomRotation(5),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n])\n\ntransform_test = transforms.Compose([\n    ToRGB(),\n    transforms.Resize(32),\n    transforms.CenterCrop(32),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n])\n\ntransform_validation = transforms.Compose([\n    ToRGB(),\n    transforms.Resize(32),\n    transforms.CenterCrop(32),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n])\n\nclass AnimalDataset(Dataset):\n    def __init__(self, hf_dataset, transform=None):\n        self.dataset = hf_dataset\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.dataset)\n\n    def __getitem__(self, idx):\n        image = self.dataset[idx]['image']\n        caption_id = self.dataset[idx]['lable']\n        if self.transform:\n            image = self.transform(image)\n        return image, caption_id\n\ntrain_dataset = AnimalDataset(dataset['train'], transform=transform_train)\ntest_dataset  = AnimalDataset(dataset['test'], transform=transform_test)\nvalidation_dataset = AnimalDataset(dataset['validation'], transform=transform_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T13:32:15.134564Z","iopub.execute_input":"2025-09-12T13:32:15.134856Z","iopub.status.idle":"2025-09-12T13:32:16.067795Z","shell.execute_reply.started":"2025-09-12T13:32:15.134838Z","shell.execute_reply":"2025-09-12T13:32:16.066927Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# train_dataset[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T13:32:16.068694Z","iopub.execute_input":"2025-09-12T13:32:16.068960Z","iopub.status.idle":"2025-09-12T13:32:16.836065Z","shell.execute_reply.started":"2025-09-12T13:32:16.068938Z","shell.execute_reply":"2025-09-12T13:32:16.835477Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"batch_size = 64\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size)\ntest_dataloader = DataLoader(test_dataset, batch_size=batch_size)\nvalidation_dataloader = DataLoader(validation_dataset, batch_size=batch_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T14:39:54.071640Z","iopub.execute_input":"2025-09-12T14:39:54.072197Z","iopub.status.idle":"2025-09-12T14:39:54.076296Z","shell.execute_reply.started":"2025-09-12T14:39:54.072172Z","shell.execute_reply":"2025-09-12T14:39:54.075783Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass ResidualBlock(nn.Module):\n    def __init__(self, inchannel, outchannel, stride=1):\n        super(ResidualBlock, self).__init__()\n        self.left = nn.Sequential(\n            nn.Conv2d(inchannel, outchannel, kernel_size=3, stride=stride, padding=1, bias=False),\n            nn.BatchNorm2d(outchannel),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(outchannel, outchannel, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.BatchNorm2d(outchannel)\n        )\n        self.shortcut = nn.Sequential()\n        if stride != 1 or inchannel != outchannel:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(inchannel, outchannel, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(outchannel)\n            )\n            \n    def forward(self, x):\n        out = self.left(x)\n        out = out + self.shortcut(x)\n        out = F.relu(out)\n        \n        return out\n\nclass ResNet(nn.Module):\n    def __init__(self, ResidualBlock, num_classes=0):\n        super(ResNet, self).__init__()\n        self.inchannel = 64\n        self.conv1 = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU()\n        )\n        self.layer1 = self.make_layer(ResidualBlock, 64, 2, stride=1)\n        self.layer2 = self.make_layer(ResidualBlock, 128, 2, stride=2)\n        self.layer3 = self.make_layer(ResidualBlock, 256, 2, stride=2)        \n        self.layer4 = self.make_layer(ResidualBlock, 512, 2, stride=2)        \n        self.fc = nn.Linear(512, num_classes)\n        \n    def make_layer(self, block, channels, num_blocks, stride):\n        strides = [stride] + [1] * (num_blocks - 1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.inchannel, channels, stride))\n            self.inchannel = channels\n        return nn.Sequential(*layers)\n    \n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = F.avg_pool2d(out, 4)\n        out = out.view(out.size(0), -1)\n        out = self.fc(out)\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T13:32:16.854030Z","iopub.execute_input":"2025-09-12T13:32:16.854190Z","iopub.status.idle":"2025-09-12T13:32:16.865934Z","shell.execute_reply.started":"2025-09-12T13:32:16.854177Z","shell.execute_reply":"2025-09-12T13:32:16.865370Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"lenght = len(class_names)\n\ndef ResNet18():\n    return ResNet(ResidualBlock, num_classes = lenght)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T13:32:16.866568Z","iopub.execute_input":"2025-09-12T13:32:16.866743Z","iopub.status.idle":"2025-09-12T13:32:16.889361Z","shell.execute_reply.started":"2025-09-12T13:32:16.866730Z","shell.execute_reply":"2025-09-12T13:32:16.888815Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = ResNet18().to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T13:32:16.890061Z","iopub.execute_input":"2025-09-12T13:32:16.890293Z","iopub.status.idle":"2025-09-12T13:32:17.504760Z","shell.execute_reply.started":"2025-09-12T13:32:16.890269Z","shell.execute_reply":"2025-09-12T13:32:17.504160Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"state_dict = torch.load('/kaggle/input/resnet2/cifar100_best_model_resnet18_seed2023.pth')\n\n\nmodel.load_state_dict(state_dict, strict=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T14:32:03.886350Z","iopub.execute_input":"2025-09-12T14:32:03.886761Z","iopub.status.idle":"2025-09-12T14:32:04.006269Z","shell.execute_reply.started":"2025-09-12T14:32:03.886738Z","shell.execute_reply":"2025-09-12T14:32:04.005584Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"_IncompatibleKeys(missing_keys=['conv1.0.weight', 'conv1.1.weight', 'conv1.1.bias', 'conv1.1.running_mean', 'conv1.1.running_var', 'layer1.0.left.0.weight', 'layer1.0.left.1.weight', 'layer1.0.left.1.bias', 'layer1.0.left.1.running_mean', 'layer1.0.left.1.running_var', 'layer1.0.left.3.weight', 'layer1.0.left.4.weight', 'layer1.0.left.4.bias', 'layer1.0.left.4.running_mean', 'layer1.0.left.4.running_var', 'layer1.1.left.0.weight', 'layer1.1.left.1.weight', 'layer1.1.left.1.bias', 'layer1.1.left.1.running_mean', 'layer1.1.left.1.running_var', 'layer1.1.left.3.weight', 'layer1.1.left.4.weight', 'layer1.1.left.4.bias', 'layer1.1.left.4.running_mean', 'layer1.1.left.4.running_var', 'layer2.0.left.0.weight', 'layer2.0.left.1.weight', 'layer2.0.left.1.bias', 'layer2.0.left.1.running_mean', 'layer2.0.left.1.running_var', 'layer2.0.left.3.weight', 'layer2.0.left.4.weight', 'layer2.0.left.4.bias', 'layer2.0.left.4.running_mean', 'layer2.0.left.4.running_var', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.weight', 'layer2.0.shortcut.1.bias', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.1.left.0.weight', 'layer2.1.left.1.weight', 'layer2.1.left.1.bias', 'layer2.1.left.1.running_mean', 'layer2.1.left.1.running_var', 'layer2.1.left.3.weight', 'layer2.1.left.4.weight', 'layer2.1.left.4.bias', 'layer2.1.left.4.running_mean', 'layer2.1.left.4.running_var', 'layer3.0.left.0.weight', 'layer3.0.left.1.weight', 'layer3.0.left.1.bias', 'layer3.0.left.1.running_mean', 'layer3.0.left.1.running_var', 'layer3.0.left.3.weight', 'layer3.0.left.4.weight', 'layer3.0.left.4.bias', 'layer3.0.left.4.running_mean', 'layer3.0.left.4.running_var', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.weight', 'layer3.0.shortcut.1.bias', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.1.left.0.weight', 'layer3.1.left.1.weight', 'layer3.1.left.1.bias', 'layer3.1.left.1.running_mean', 'layer3.1.left.1.running_var', 'layer3.1.left.3.weight', 'layer3.1.left.4.weight', 'layer3.1.left.4.bias', 'layer3.1.left.4.running_mean', 'layer3.1.left.4.running_var', 'layer4.0.left.0.weight', 'layer4.0.left.1.weight', 'layer4.0.left.1.bias', 'layer4.0.left.1.running_mean', 'layer4.0.left.1.running_var', 'layer4.0.left.3.weight', 'layer4.0.left.4.weight', 'layer4.0.left.4.bias', 'layer4.0.left.4.running_mean', 'layer4.0.left.4.running_var', 'layer4.0.shortcut.0.weight', 'layer4.0.shortcut.1.weight', 'layer4.0.shortcut.1.bias', 'layer4.0.shortcut.1.running_mean', 'layer4.0.shortcut.1.running_var', 'layer4.1.left.0.weight', 'layer4.1.left.1.weight', 'layer4.1.left.1.bias', 'layer4.1.left.1.running_mean', 'layer4.1.left.1.running_var', 'layer4.1.left.3.weight', 'layer4.1.left.4.weight', 'layer4.1.left.4.bias', 'layer4.1.left.4.running_mean', 'layer4.1.left.4.running_var', 'fc.weight', 'fc.bias'], unexpected_keys=['model_state_dict', 'optimizer_state_dict'])"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"from torch.optim.lr_scheduler import OneCycleLR\n\nloss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\nscheduler = OneCycleLR(\n    optimizer,\n    max_lr=1e-3,\n    steps_per_epoch=len(train_dataloader),\n    epochs=50\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T14:41:31.056752Z","iopub.execute_input":"2025-09-12T14:41:31.057244Z","iopub.status.idle":"2025-09-12T14:41:31.061942Z","shell.execute_reply.started":"2025-09-12T14:41:31.057226Z","shell.execute_reply":"2025-09-12T14:41:31.061146Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"class EarlyStopping:\n    def __init__(self, patience=5, min_delta=0):\n        self.patience = patience\n        self.min_delta = min_delta\n        self.counter = 0\n        self.best_loss = None\n        self.early_stop = False\n\n    def __call__(self, val_loss):\n        if self.best_loss is None:\n            self.best_loss = val_loss\n        elif val_loss > self.best_loss - self.min_delta:\n            self.counter += 1\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_loss = val_loss\n            self.counter = 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T14:41:35.367404Z","iopub.execute_input":"2025-09-12T14:41:35.368119Z","iopub.status.idle":"2025-09-12T14:41:35.372948Z","shell.execute_reply.started":"2025-09-12T14:41:35.368094Z","shell.execute_reply":"2025-09-12T14:41:35.372068Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"def train(train_loader, val_loader, model, loss_fn, optimizer, scheduler):\n    early_stopping = EarlyStopping(patience=7, min_delta=1e-4)\n    model.train()\n    size = len(train_loader.dataset)\n\n    for batch, (X, y) in enumerate(train_loader):\n        X, y = X.to(device), y.to(device)\n\n        # Compute prediction and loss\n        pred = model(X)\n        loss = loss_fn(pred, y)\n\n        # Backpropagation\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        scheduler.step() # Step scheduler per batch!\n\n        if batch % 100 == 0:\n            loss, current = loss.item(), (batch + 1) * len(X)\n            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n\n    model.eval()\n    val_loss = 0.0\n    with torch.no_grad():\n        for X_val, y_val in val_loader:\n            X_val, y_val = X_val.to(device), y_val.to(device)\n            pred_val = model(X_val)\n            val_loss += loss_fn(pred_val, y_val).item()\n    val_loss /= len(val_loader)\n    print(f\"Validation Loss: {val_loss:.6f}\")\n\n    # Check early stopping\n    early_stopping(val_loss)\n    if early_stopping.early_stop:\n        print(f\"Early stopping triggered at epoch {epoch+1}\")\n        return True ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T14:41:38.273684Z","iopub.execute_input":"2025-09-12T14:41:38.273927Z","iopub.status.idle":"2025-09-12T14:41:38.280164Z","shell.execute_reply.started":"2025-09-12T14:41:38.273910Z","shell.execute_reply":"2025-09-12T14:41:38.279625Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"def test(dataloader, model, loss_fn):\n    size = len(dataloader.dataset)\n    num_batches = len(dataloader)\n    model.eval()\n    test_loss, correct = 0, 0\n    with torch.no_grad():\n        for X, y in dataloader:\n            X, y = X.to(device), y.to(device)\n            pred = model(X)\n            test_loss += loss_fn(pred, y).item()\n            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n    test_loss /= num_batches\n    correct /= size\n    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T14:41:41.453158Z","iopub.execute_input":"2025-09-12T14:41:41.453424Z","iopub.status.idle":"2025-09-12T14:41:41.458570Z","shell.execute_reply.started":"2025-09-12T14:41:41.453406Z","shell.execute_reply":"2025-09-12T14:41:41.457920Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"def validation(dataloader, model, loss_fn):\n    size = len(dataloader.dataset)\n    num_batches = len(dataloader)\n    model.eval()\n    test_loss, correct = 0, 0\n    with torch.no_grad():\n        for X, y in dataloader:\n            X, y = X.to(device), y.to(device)\n            pred = model(X)\n            test_loss += loss_fn(pred, y).item()\n            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n    test_loss /= num_batches\n    correct /= size\n    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T14:41:43.711741Z","iopub.execute_input":"2025-09-12T14:41:43.712609Z","iopub.status.idle":"2025-09-12T14:41:43.717246Z","shell.execute_reply.started":"2025-09-12T14:41:43.712583Z","shell.execute_reply":"2025-09-12T14:41:43.716576Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"epochs = 70\nfor t in range(epochs):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    stop = train(train_dataloader, validation_dataloader, model, loss_fn, optimizer, scheduler)\n    test(test_dataloader, model, loss_fn)\n    if stop:\n        break\nprint(\"Done!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-12T14:41:46.550252Z","iopub.execute_input":"2025-09-12T14:41:46.550550Z","iopub.status.idle":"2025-09-12T14:49:06.433463Z","shell.execute_reply.started":"2025-09-12T14:41:46.550530Z","shell.execute_reply":"2025-09-12T14:49:06.432472Z"}},"outputs":[{"name":"stdout","text":"Epoch 1\n-------------------------------\nloss: 3.262585  [   64/37289]\nloss: 3.246325  [ 6464/37289]\nloss: 3.193447  [12864/37289]\nloss: 3.351963  [19264/37289]\nloss: 3.750714  [25664/37289]\nloss: 3.663683  [32064/37289]\nValidation Loss: 4.418932\nTest Error: \n Accuracy: 12.6%, Avg loss: 4.455565 \n\nEpoch 2\n-------------------------------\nloss: 3.399457  [   64/37289]\nloss: 3.252271  [ 6464/37289]\nloss: 3.226799  [12864/37289]\nloss: 3.463130  [19264/37289]\nloss: 3.373545  [25664/37289]\nloss: 3.538735  [32064/37289]\nValidation Loss: 4.723850\nTest Error: \n Accuracy: 9.5%, Avg loss: 4.761127 \n\nEpoch 3\n-------------------------------\nloss: 3.414966  [   64/37289]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/373323184.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {t+1}\\n-------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/1870579257.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, val_loader, model, loss_fn, optimizer, scheduler)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/2440614729.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mcaption_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaption_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \"\"\"\n\u001b[1;32m    668\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dimensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(img, padding, fill, padding_mode)\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0m_log_api_usage_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/_functional_pil.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(img, padding, fill, padding_mode)\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mImageOps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mborder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/ImageOps.py\u001b[0m in \u001b[0;36mexpand\u001b[0;34m(image, border, fill)\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0mpalette\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpalette\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mputpalette\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpalette\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpalette\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mnew\u001b[0;34m(mode, size, color)\u001b[0m\n\u001b[1;32m   3106\u001b[0m             \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpalette\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImagePalette\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImagePalette\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3107\u001b[0m             \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpalette\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor_ints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3108\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":34},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}